{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import time\r\n",
    "import numpy as np  # install\r\n",
    "import keras  # install\r\n",
    "from keras.regularizers import l1, l2\r\n",
    "from keras import backend as K\r\n",
    "from keras.utils import np_utils\r\n",
    "#from keras.utils import plot_model\r\n",
    "#from keras.optimizers import SGD\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.models import load_model\r\n",
    "from keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\r\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\r\n",
    "import matplotlib.pyplot as plt  # install\r\n",
    "\r\n",
    "# from image_util import show_intermediate_output, show_heatmap\r\n",
    "\r\n",
    "np.random.seed(1337)\r\n",
    "# os.environ[\"PATH\"] += os.pathsep + \\\r\n",
    "#                       'C:/Program Files (x86)/Graphviz2.38/bin'\r\n",
    "\r\n",
    "epochs = 50\r\n",
    "nb_classes = 5\r\n",
    "nb_per_class = 10000\r\n",
    "batch_size = 32\r\n",
    "learning_rate = 0.0001\r\n",
    "activation = 'relu'\r\n",
    "width, height, depth = 278, 158, 1\r\n",
    "nb_filters1, nb_filters2 = 5, 10\r\n",
    "train_proportion = 0.8\r\n",
    "valid_proportion = 0.1\r\n",
    "test_proportion = 0.1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def set_model(lr=learning_rate, decay=1e-6, momentum=0.9):\r\n",
    "    model = Sequential()\r\n",
    "    if K.image_data_format() == 'channels_first':\r\n",
    "        model.add(SeparableConv2D(nb_filters1, kernel_size=(3, 3), kernel_regularizer=l2(0.01),\r\n",
    "                                  input_shape=(depth, height, width), name='conv1'))\r\n",
    "    else:\r\n",
    "        model.add(SeparableConv2D(nb_filters1, kernel_size=(3, 3),\r\n",
    "                                  input_shape=(height, width, depth), name='conv1'))\r\n",
    "    model.add(Activation(activation))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpooling1'))\r\n",
    "    model.add(Dropout(0.5))\r\n",
    "\r\n",
    "    model.add(SeparableConv2D(nb_filters2, kernel_size=(3, 3),\r\n",
    "                              kernel_regularizer=l2(0.01), name='conv2'))\r\n",
    "    model.add(Activation(activation))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='maxpooling2'))\r\n",
    "    model.add(Dropout(0.5))\r\n",
    "\r\n",
    "    model.add(Flatten())\r\n",
    "    model.add(Dense(128, kernel_regularizer=l2(\r\n",
    "        0.01), name='dense1'))  # Full connection\r\n",
    "    model.add(Activation(activation))\r\n",
    "    model.add(Dropout(0.5))\r\n",
    "\r\n",
    "    model.add(Dense(nb_classes, name='dense2'))  # output\r\n",
    "    model.add(Activation('softmax'))\r\n",
    "\r\n",
    "    sgd = SGD(lr=learning_rate, decay=decay, momentum=momentum,\r\n",
    "              nesterov=True)  # optimizer\r\n",
    "    model.compile(loss='categorical_crossentropy',\r\n",
    "                  optimizer=sgd, metrics=['accuracy'])\r\n",
    "    model.summary()  # 输出模型各层的参数状况\r\n",
    "    return model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LossHistory(keras.callbacks.Callback):\r\n",
    "    # 损失历史记录 输出参数变化图像\r\n",
    "    def on_train_begin(self, logs={}):\r\n",
    "        self.losses = {'batch': [], 'epoch': []}\r\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\r\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\r\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\r\n",
    "\r\n",
    "    def on_batch_end(self, batch, logs={}):\r\n",
    "        self.losses['batch'].append(logs.get('loss'))\r\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\r\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\r\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\r\n",
    "\r\n",
    "    def on_epoch_end(self, batch, logs={}):\r\n",
    "        self.losses['epoch'].append(logs.get('loss'))  # train loss\r\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))  # train acc\r\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\r\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\r\n",
    "\r\n",
    "    def loss_plot(self, loss_type):\r\n",
    "        iters = range(len(self.losses[loss_type]))\r\n",
    "        plt.figure(num='Change of parameters')\r\n",
    "        # train acc\r\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\r\n",
    "        # train loss\r\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\r\n",
    "\r\n",
    "        if loss_type == 'epoch':\r\n",
    "            # val_acc\r\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\r\n",
    "            # val_loss\r\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\r\n",
    "\r\n",
    "        plt.title('epoch=' + str(epochs) + ',lr=' + str(learning_rate) + ',batch_size=' + str(batch_size)\r\n",
    "                  + '\\nactivation=' + activation + ',nb_classes=' + str(nb_classes) + ',nb_per_class=' + str(\r\n",
    "            nb_per_class))\r\n",
    "        plt.grid(True)\r\n",
    "        plt.xlabel(loss_type)\r\n",
    "        plt.ylabel('acc-loss')\r\n",
    "        plt.legend(loc=\"upper right\")\r\n",
    "        now = time.strftime('%Y-%m-%d@%H-%M-%S', time.localtime(time.time()))\r\n",
    "        plt.savefig('./parameter/' + now + '.jpg')\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "\r\n",
    "history = LossHistory()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model, X_train, Y_train, X_val, Y_val):\r\n",
    "    # tensorboard = keras.callbacks.TensorBoard(\r\n",
    "    #     log_dir='F:/Log/', histogram_freq=1)\r\n",
    "\r\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True,\r\n",
    "              verbose=1, validation_data=(X_val, Y_val), callbacks=[history])\r\n",
    "    model.save('model.h5')\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def test_model(X_test, Y_test):\r\n",
    "    model = load_model('model.h5')\r\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
    "    return score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data():\r\n",
    "    #train_data = np.load('train_data.npy',allow_pickle=True)[:nb_per_class]\r\n",
    "    train_data = np.load('train_data.npy',allow_pickle=True)[:nb_per_class]\r\n",
    "    train_img = train_data[:, 0]\r\n",
    "    train_label = train_data[:, 1]\r\n",
    "\r\n",
    "    images = []\r\n",
    "    for img in train_img:\r\n",
    "        img_ndarray = np.asarray(img, dtype='float64') / 255\r\n",
    "        data = np.ndarray.flatten(img_ndarray)\r\n",
    "        data = data.astype('float32')\r\n",
    "        images.append(data)\r\n",
    "    images = np.asarray(images)\r\n",
    "\r\n",
    "    labels = []\r\n",
    "    for label in train_label:\r\n",
    "        if label == [1, 0, 0, 0, 0]:\r\n",
    "            labels.append(0)\r\n",
    "        elif label == [0, 1, 0, 0, 0]:\r\n",
    "            labels.append(1)\r\n",
    "        elif label == [0, 0, 1, 0, 0]:\r\n",
    "            labels.append(2)\r\n",
    "        elif label == [0, 0, 0, 1, 0]:\r\n",
    "            labels.append(3)\r\n",
    "        elif label == [0, 0, 0, 0, 0]:\r\n",
    "            labels.append(4)\r\n",
    "            \r\n",
    "    labels = np.asarray(labels)\r\n",
    "\r\n",
    "    train_per_category = int(nb_per_class * train_proportion)\r\n",
    "    valid_per_category = int(nb_per_class * valid_proportion)\r\n",
    "\r\n",
    "    X_train = images[:train_per_category]\r\n",
    "    X_val = images[train_per_category:train_per_category + valid_per_category]\r\n",
    "    X_test = images[train_per_category + valid_per_category:]\r\n",
    "\r\n",
    "    y_train = labels[:train_per_category]\r\n",
    "    y_val = labels[train_per_category:train_per_category + valid_per_category]\r\n",
    "    y_test = labels[train_per_category + valid_per_category:]\r\n",
    "    rval = [(X_train, y_train), (X_val, y_val), (X_test, y_test)]\r\n",
    "    return rval\r\n",
    "\r\n",
    "\r\n",
    "def main():\r\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data()\r\n",
    "    if K.image_data_format() == 'channels_first':\r\n",
    "        X_train = X_train.reshape(X_train.shape[0], depth, height, width)\r\n",
    "        X_val = X_val.reshape(X_val.shape[0], depth, height, width)\r\n",
    "        X_test = X_test.reshape(X_test.shape[0], depth, height, width)\r\n",
    "    else:\r\n",
    "        X_train = X_train.reshape(X_train.shape[0], height, width, depth)\r\n",
    "        X_val = X_val.reshape(X_val.shape[0], height, width, depth)\r\n",
    "        X_test = X_test.reshape(X_test.shape[0], height, width, depth)\r\n",
    "\r\n",
    "    print('X_train shape:', X_train.shape)\r\n",
    "    print('Class number:', nb_classes)\r\n",
    "    print(X_train.shape[0], 'train samples')\r\n",
    "    print(X_val.shape[0], 'validate samples')\r\n",
    "    print(X_test.shape[0], 'test samples')\r\n",
    "\r\n",
    "    # convert class vectors to binary class matrices\r\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\r\n",
    "    Y_val = np_utils.to_categorical(y_val, nb_classes)\r\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\r\n",
    "\r\n",
    "    model = set_model()\r\n",
    "\r\n",
    "    # plot_model(model, to_file='model.png', show_shapes=True)\r\n",
    "\r\n",
    "    start = time.perf_counter()\r\n",
    "    model = train_model(model, X_train, Y_train, X_val, Y_val)\r\n",
    "    end = time.perf_counter()\r\n",
    "\r\n",
    "    #pred_classes = model.predict_classes(X_test, verbose=0)\r\n",
    "    pred_classes = model.predict(X_test) \r\n",
    "    pred_classes = np.argmax(pred_classes,axis=1)\r\n",
    "\r\n",
    "    test_accuracy = np.mean(np.equal(y_test, pred_classes))\r\n",
    "    right = np.sum(np.equal(y_test, pred_classes))\r\n",
    "\r\n",
    "    print('Total training time:', end - start)\r\n",
    "    print('Test number:', len(Y_test))\r\n",
    "    print('Test right:', right)\r\n",
    "    print('Test wrong:', len(Y_test) - right)\r\n",
    "    print('Test accuracy:', test_accuracy)\r\n",
    "\r\n",
    "    history.loss_plot('epoch')\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    main()\r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}